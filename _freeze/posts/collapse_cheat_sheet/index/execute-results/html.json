{
  "hash": "f406facb2c22d17eb1a83ed6c6fc0240",
  "result": {
    "markdown": "---\ntitle: \"Collapse Cheat sheet\"\ndescription: \"Syntax translation from dplyr and data.tablen to collapse\"\nauthor: \"PIP Technical team\"\ndate: \"03/13/2025\"\ncategories: [collapse, data.table, dplyr, efficiency]\nformat:\n  html:\n    toc: true\neditor_options: \n  chunk_output_type: console\nexecute:\n  output: false\n---\n\n\n## Introduction\n\nThis post is inpired in the Atreba's blog: [A data.table and dplyr tour](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/). The objective of this post is to complement Atreba's one with the syntax of the [`{collapse}`](https://sebkrantz.github.io/collapse/) R package.\n\n## Basic understanding of the three packages\n\n### dplyr\n\nblach\n\n### data.table\n\nblah\n\n### collapse\n\nblah\n\n## Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(collapse)\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell hash='index_cache/html/data_33e15e4e5bf03ac858215d71d97dfaca'}\n\n```{.r .cell-code}\nset.seed(42)\n\n# Number of rows\nn <- 10000\n\n# # Generate fake data\n# df <- data.frame(\n#   id1 = 1:n,  # Unique ID\n#   id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n#   dt = seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n),  # Dates\n#   tm = format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n#                          by = \"hour\", length.out = n), \"%H:%M:%S\"),  # Time\n#   ch = sample(c(\"A\", \"B\", \"C\", \"D\"), n, replace = TRUE),  # Character\n#   int = sample(1:100, n, replace = TRUE),  # Integer\n#   log = sample(c(TRUE, FALSE), n, replace = TRUE),  # Logical\n#   realf = runif(n, 1, 100),  # Real (float),\n#   reald = runif(n),  # Real ,\n#   fct = factor(sample(c(\"X\", \"Y\", \"Z\"), n, replace = TRUE))  # Factor\n# )\n\nset.seed(42)\n\n# Number of rows\nn <- 10000\n\n# Generate fake data with some NAs\ndf <- data.frame(\n  id1 = 1:n,  # Unique ID\n  id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n  dt = sample(c(seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n), NA), n, replace = TRUE),  # Dates with NAs\n  tm = sample(c(format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n                                  by = \"hour\", length.out = n), \"%H:%M:%S\"), NA), n, replace = TRUE),  # Time with NAs\n  ch = sample(c(\"A\", \"B\", \"C\", \"D\", NA), n, replace = TRUE, prob = c(0.24, 0.24, 0.24, 0.24, 0.04)),  # Character with some NAs\n  int = sample(c(1:100, NA), n, replace = TRUE),  # Integer with some NAs\n  log = sample(c(TRUE, FALSE, NA), n, replace = TRUE, prob = c(0.49, 0.49, 0.02)),  # Logical with some NAs\n  realf = sample(c(runif(n, 1, 100), NA), n, replace = TRUE),  # Real (float) with some NAs\n  reald = sample(c(runif(n), NA), n, replace = TRUE),  # Real with some NAs\n  fct = factor(sample(c(\"X\", \"Y\", \"Z\", NA), n, replace = TRUE, prob = c(0.32, 0.32, 0.32, 0.04)))  # Factor with some NAs\n)\n\n# Print summary to check distribution of NAs\nsummary(df)\n\n\n# Ensure uniqueness\ndf <- unique(df, by = c(\"id1\", \"id2\"))\ndt <- setDT(df)\ntb <- as_tibble(df)\n```\n:::\n\n\n## Basic use\n\n### Filtering rows\n\n#### Filter rows using indices\n\n::: panel-tabset\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# super efficient\ndf |> \n  ss(2:5)\n\n# efficient\ndf |> \n  fsubset(2:5)\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[2:5]\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  slice(2:5)\n\n# or using index like any data.frame\ntb[2:5,]\n\n# you need to add the comma. Otherwise, you get a different result\ntb[2:5]\n```\n:::\n\n:::\n\n#### Discard rows using negative indices\n\n::: panel-tabset\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  ss(-c(2:5)) |> \n  head(4)\n\ndf |> \n  ss(-c(2:5)) |> \n  head(4)\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[!2:5] |> \n  head(4)\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  slice(-(2:5)) |> \n  head(4)\n```\n:::\n\n:::\n\n#### Filter rows using conditions\n\n::: panel-tabset\n\n::: {.cell}\n\n```{.r .cell-code}\n# using named objects to filter data\nch  <- \"A\" # data has this as variable name\nfct <- \"A\" # data has this as variable name\nx  <- \"A\"\n```\n:::\n\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  fsubset(ch == \"A\" & id1 == 6)\n\ndf |> \n  fsubset(ch == x & id1 == 6)\n\n# This works\ndf |> \n  fsubset(ch == ch & id1 == 6)\n\n# This does not work\ndf |> \n  fsubset(ch == fct & id1 == 6)\n\n# This through error\ndf |> \n  fsubset(ch == get(fct) & id1 == 6) |> \n  try()\n\n# This works\ndf |> \n  fsubset(ch == get(\"fct\", envir = -2) & id1 == 6) \n\n# NOTE: is there a better way?\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[ch == \"A\" & id1 == 6]\n\ndt[ch == x & id1 == 6]\n\ndt[ch ==ch & id1 == 6]\n\n# this does not work\ndt[ch == fct & id1 == 6]\n\n\ndt[ch == eval(fct) & id1 == 6]\n\n# These work but they are  verbose\ndt[ch == get(\"fct\", envir = parent.frame()) & id1 == 6]\ndt[ch == get(\"fct\", envir = -2) & id1 == 6]\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  filter(ch == \"A\" & id1 == 6)\n\ntb |> \n  filter(ch == x & id1 == 6)\n\ntb |> \n  filter(ch == ch & id1 == 6)\n\n# does not work\ntb |> \n  filter(ch == fct & id1 == 6)\n\n# works really well\ntb |> \n  filter(ch == !!fct & id1 == 6)\n```\n:::\n\n:::\n\n#### Filter unique rows \n\n::: panel-tabset\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing duplicate rows based on the values of one or more columns \n```\n:::\n\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove duplicate rows\ndf |>\n  funique()\n\n# Keeps only one row per unique value in id2\ndf |>\n  funique(cols = \"int\") # selecting column by col name \ndf |>\n  funique(cols = 6)     # selecting column by indices\ndf |>\n  funique(cols = names(df) %in% \"int\") # with logical condition\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n # Remove duplicate rows\ndt |>\n  unique()\n\n# Keeps only one row per unique value in id2\ndt |>\n  unique(by = \"id2\")  \n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove duplicate rows\ntb |>\n  distinct()\n\n# Keeps only one row per unique id1\ntb |> distinct(id1, .keep_all = TRUE) # keep all col\n```\n:::\n\n:::\n\n#### Discard rows with missing values\n::: panel-tabset\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ndf |>\n  na_omit()\n\n# Discard rows with NA value for selected col\ndf |>\n  na_omit(cols = \"ch\")\n\n# More flexible options:\n# Remove rows where more than 50% of values are missing\ndf |>\n  na_omit(prop = 0.5)\n```\n:::\n\n\n\n## data.table\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ndt |>\n  na_omit()\n\n# Discard rows with NA value for selected col\ndt <- dt[!is.na(ch)]\n```\n:::\n\n\n\n## tidyverse\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ntb |>\n  tidyr::drop_na()\n\n# Discard rows with NA value for selected col\ntb |> \n  tidyr::drop_na(ch)\n```\n:::\n\n:::\n\n#### Other filters: slice options\n\n::: panel-tabset\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  fslice(n = 3)                 # First 3 rows\ndf |>\n  fslice(n   = 3, \n         how = \"last\")          # Last 3 rows\ndf |>\n  fslice(n = 0.1)               # Fraction of rows: first 10% of rows\n\nfslice(n        = 3, \n       how      = \"min\", \n       order.by = int)          # 3 obs with lowest int\n\n# TODO: add fslicev()\n```\n:::\n\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Frist 3 rows\ndt[1:3, ]   # First 3 rows, all columns\n\n\n# Last 3 rows\ndt[(.N-2):.N]  # .N gives the total number of rows\n\n# Fraction of rows: first 10% of rows\ndt[1:(.N * 0.1)]\n\n\n# 3 obs with lowest int\ndt[order(int)][1:3]\n```\n:::\n\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First 3 rows\ntb |>\n  slice_head(n = 3)\n\n# Last 3 rows\ntb |>\n  slice_tail(n = 3)\n\n# Fraction of rows: first 10% of rows\ntb |>\n  slice_head(prop = 0.1)\n\n# 3 obs with lowest int\ntb |>\n  slice_min(order_by = int, \n            n        = 3) # all rows\n\ntb |>\n slice_min(order_by = int, \n           n        = 3, \n           with_ties = FALSE) \n```\n:::\n\n:::\n\n### Sort rows\n\n#### Sort rows by column(s)\n\n::: panel-tabset\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  roworder(id1)  \n\ndf |>\n  roworder(-id2)      # Sort by decreasing order of id2\n\ndf |>\n  roworder(id1, -id2) # Sort by multiple cols \n```\n:::\n\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[order(id2)]    # This makes a copy\n\nsetorder(dt, id2) # To modify by reference  \n\ndt[order(-id2)]   # Sort by decreasing order\n\ndt[order(id1, -id2)] # Sort by multiple cols \n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |>\n  arrange(id2)\n\ntb |>\n  arrange(desc(id2)) # Sort by decreasing order\n\n# Sort by multiple cols \ndf |>\n   arrange(id1, desc(id2))\n```\n:::\n\n\n::: \n\n### Select columns\n\n#### Select one or more columns\n\n::: panel-tabset \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select one column using an index, not recommended, or column name\n# select multiple columns \n```\n:::\n\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Select one column   ####\n# _________________________ \n\n# by index\ndf |>\n  fselect(2)\n\ndf |>\n  slt(2) # shorthand for fselect\n\n# by name\n\ndf |>\n  fselect(id2)  # returns a dataframe \n\n## Select multiple columns ####\n# _____________________________ \n\ndf |>\n  fselect(id1, id2, fct)\n\ndf |>\n  fselect(id1, ch:fct)\n```\n:::\n\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Select one column   ####\n# _________________________ \n\n# by index\ndt[[3]]  # returns a vector\ndt[, 3]  # returns a data.table\n\n# by name\ndt[, list(id2)] # returns a data.table\ndt[, .(id2)]    # returns a data.table (. is an alias for list)\ndt[, \"id2\"]     # returns a data.table\ndt[, id2]       # returns a vector\ndt[[\"id2\"]]     # returns a vector\n\n## Select multiple columns ####\n# _____________________________ \n\ndt[, .(id1, id2, int)]\ndt[, list(id1, id2, int)]\ndt[, id2:int] # select columns between id2 and int\n```\n:::\n\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Select one column   ####\n# _________________________ \n\ntb |>\n  select(id2)               # returns a tibble\n\npull(tb, id2, name = ch)    # returns a (named) vector\ntb[, \"id2\"]                 # returns a tibble\ntb[[\"id2\"]]                 # returns a vector\n\n## Select multiple columns ####\n# _____________________________ \n\ndf |>\n  select(id1, id2, ch)\ndf |>\n  select(id1, ch:fct)\n```\n:::\n\n\n\n:::\n\n#### Exclude columns \n\n::: panel-tabset \n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exclude columns by column names \ndf |>\n  fselect(-dt, -tm)\n\n# Using a character vector \ncols <- c(\"dt\", \"tm\")\n\ndf |>\n  fselect(-cols)  # does not work \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in -cols: invalid argument to unary operator\n```\n:::\n\n```{.r .cell-code}\ndf |>\n  fselect(!cols) # does not work \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in !cols: invalid argument type\n```\n:::\n\n```{.r .cell-code}\n# what is a better way to do this?\n```\n:::\n\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exclude columns by column names \ndt[, !c(\"dt\", \"tm\")]\n\n# Using a character vector \ncols <- c(\"dt\", \"tm\")\n\ndt[, ..cols] \n# .. prefix means 'one-level up', as cols is outside the parent environment \n\ndt[, !..cols] # or dt[, -..cols]\n```\n:::\n\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exclude columns by column names \ntb |>\n  select( -dt, -tm)\n\n# Using a character vector \ncols <- c(\"dt\", \"tm\")\n\ntb |>\n  select(all_of(cols))\n\ntb |>\n  select(-all_of(cols))\n```\n:::\n\n\n:::\n\n#### Other selections - not sure it is relevant, to check \n\n### Miscellaneous\n\n#### Read & write data\n\n##### Write \n\n::: panel-tabset\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# no specific functions for reading and writing data \n```\n:::\n\n\n## data.table\n\n::: {.cell}\n\n```{.r .cell-code}\nfwrite(dt, \n       \"DT.csv\")                # write to csv\n\n\nfwrite(dt, \n       \"DT.txt\", \n       sep = \"\\t\")              # write to a tab-delimited file\n```\n:::\n\n\n\n## dplyr\n\n::: {.cell}\n\n```{.r .cell-code}\nreadr::write_csv(tb, \n                 \"tb.csv\")  # write to csv\n\nreadr::write_delim(tb, \n                   \"tb.txt\", \n                   delim = \"\\t\")  # write to a tab-delimited file\n```\n:::\n\n\n:::\n\n##### Read\n\n::: panel-tabset\n\n## collapse\n\n::: {.cell}\n\n```{.r .cell-code}\n# no specific functions for reading and writing data \n```\n:::\n\n\n## data.table\n\n::: {.cell}\n\n```{.r .cell-code}\nfread(\"dt.csv\")   # read csv\n# fread(\"DT.csv\", verbose = TRUE) # full details\n\nfread(\"dt.txt\", sep = \"\\t\") # read tab-delimited file\n\n# Read and rbind several files\nrbindlist(\n  lapply(c(\"dt.csv\", \"dt.csv\"), \n         fread))\n```\n:::\n\n\n\n## dplyr\n\n::: {.cell}\n\n```{.r .cell-code}\nreadr::read_csv(\"tb.csv\")  # read csv\n\nreadr::read_delim(\"tb.txt\", \n                  delim = \"\\t\")  # read tab-delimited file\n\n# Read and rbind several files\nc(\"tb.csv\",  \"tb.csv\") |>\n  purrr::map_dfr(readr::read_csv)\n```\n:::\n\n\n:::\n\n#### Reshape data \n\n::: panel-tabset\n\n## collapse\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Long to Wide ----\nwide_pivot <- pivot(df, \n                    ids    = c(\"id1\", \"id2\", \"dt\"),  # Columns to keep\n                    values = \"int\",              # Column with values\n                    names  = \"ch\",   # Column whose values become new cols\n                    how    = \"wider\")               # Reshape to wide format\n\n# ---- Wide to Long ----\nlong_pivot <- pivot(wide_pivot, \n                    ids    = c(\"id1\", \"id2\", \"dt\"),  \n                    values = NULL,  \n                    names  = list(\"ch\", \"int\"),  \n                    how    = \"longer\")     \n```\n:::\n\n\n\n## data.table\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Long to Wide ----\nwide_dt <- dcast(dt, \n                 id1 + id2 + dt ~ ch, \n                 value.var = \"int\")\n\n# ---- Wide to Long ----\nlong_dt <- melt(wide_dt, \n                id.vars       = c(\"id1\", \"id2\", \"dt\"), \n                variable.name = \"ch\", \n                value.name    = \"int\")\n```\n:::\n\n\n\n\n## dplyr\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Long to Wide ----\ntb_wide <- tb |>\n  # rm NAs\n  filter(!is.na(ch)) |>\n  pivot_wider(names_from  = ch, \n              values_from = int)\n\n# ---- Wide to Long ----\ntb_long <- tb_wide |>\n  pivot_longer(cols      = c(\"A\", \"D\", \"C\", \"B\"),\n               values_to = \"int\",\n               names_to  = \"ch\")\n```\n:::\n\n\n:::\n\n\n#### Data Conversion\n\nTBD\n\n#### Global options affecting package operation - only in {collapse}\n\nTBD\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}