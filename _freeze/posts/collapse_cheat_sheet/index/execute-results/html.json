{
  "hash": "09d6c6f53a1d60e92c80c3c836d63d55",
  "result": {
    "markdown": "---\ntitle: \"Collapse Cheat sheet\"\ndescription: \"Syntax translation from dplyr and data.tablen to collapse\"\nauthor: \"PIP Technical team\"\ndate: \"03/13/2025\"\ncategories: [collapse, data.table, dplyr, efficiency]\nformat:\n  html:\n    toc: true\neditor_options: \n  chunk_output_type: console\nexecute:\n  output: false\n---\n\n\n## Introduction\n\nThis post is inpired in the Atreba's blog: [A data.table and dplyr tour](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/). The objective of this post is to complement Atreba's one with the syntax of the [`{collapse}`](https://sebkrantz.github.io/collapse/) R package.\n\n## Basic understanding of the three packages\n\n### dplyr\n\nblach\n\n### data.table\n\nblah\n\n### collapse\n\nblah\n\n## Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(collapse)\n```\n:::\n\n::: {.cell hash='index_cache/html/data_33e15e4e5bf03ac858215d71d97dfaca'}\n\n```{.r .cell-code}\nset.seed(42)\n\n# Number of rows\nn <- 10000\n\n# # Generate fake data\n# df <- data.frame(\n#   id1 = 1:n,  # Unique ID\n#   id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n#   dt = seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n),  # Dates\n#   tm = format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n#                          by = \"hour\", length.out = n), \"%H:%M:%S\"),  # Time\n#   ch = sample(c(\"A\", \"B\", \"C\", \"D\"), n, replace = TRUE),  # Character\n#   int = sample(1:100, n, replace = TRUE),  # Integer\n#   log = sample(c(TRUE, FALSE), n, replace = TRUE),  # Logical\n#   realf = runif(n, 1, 100),  # Real (float),\n#   reald = runif(n),  # Real ,\n#   fct = factor(sample(c(\"X\", \"Y\", \"Z\"), n, replace = TRUE))  # Factor\n# )\n\nset.seed(42)\n\n# Number of rows\nn <- 10000\n\n# Generate fake data with some NAs\ndf <- data.frame(\n  id1 = 1:n,  # Unique ID\n  id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n  dt = sample(c(seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n), NA), n, replace = TRUE),  # Dates with NAs\n  tm = sample(c(format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n                                  by = \"hour\", length.out = n), \"%H:%M:%S\"), NA), n, replace = TRUE),  # Time with NAs\n  ch = sample(c(\"A\", \"B\", \"C\", \"D\", NA), n, replace = TRUE, prob = c(0.24, 0.24, 0.24, 0.24, 0.04)),  # Character with some NAs\n  int = sample(c(1:100, NA), n, replace = TRUE),  # Integer with some NAs\n  log = sample(c(TRUE, FALSE, NA), n, replace = TRUE, prob = c(0.49, 0.49, 0.02)),  # Logical with some NAs\n  realf = sample(c(runif(n, 1, 100), NA), n, replace = TRUE),  # Real (float) with some NAs\n  reald = sample(c(runif(n), NA), n, replace = TRUE),  # Real with some NAs\n  fct = factor(sample(c(\"X\", \"Y\", \"Z\", NA), n, replace = TRUE, prob = c(0.32, 0.32, 0.32, 0.04)))  # Factor with some NAs\n)\n\n# Print summary to check distribution of NAs\nsummary(df)\n\n\n# Ensure uniqueness\ndf <- unique(df, by = c(\"id1\", \"id2\"))\ndt <- setDT(df)\ntb <- as_tibble(df)\n```\n:::\n\n\n## Basic use\n\n### Filtering rows\n\n#### Filter rows using indices\n\n::: panel-tabset\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# super efficient\ndf |> \n  ss(2:5)\n\n# efficient\ndf |> \n  fsubset(2:5)\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[2:5]\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  slice(2:5)\n\n# or using index like any data.frame\ntb[2:5,]\n\n# you need to add the comma. Otherwise, you get a different result\ntb[2:5]\n```\n:::\n\n:::\n\n#### Discard rows using negative indices\n\n::: panel-tabset\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  ss(-c(2:5)) |> \n  head(4)\n\ndf |> \n  ss(-c(2:5)) |> \n  head(4)\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[!2:5] |> \n  head(4)\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  slice(-(2:5)) |> \n  head(4)\n```\n:::\n\n:::\n\n#### Filter rows using conditions\n\n::: panel-tabset\n\n::: {.cell}\n\n```{.r .cell-code}\n# using named objects to filter data\nch  <- \"A\" # data has this as variable name\nfct <- \"A\" # data has this as variable name\nx  <- \"A\"\n```\n:::\n\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  fsubset(ch == \"A\" & id1 == 6)\n\ndf |> \n  fsubset(ch == x & id1 == 6)\n\n# This works\ndf |> \n  fsubset(ch == ch & id1 == 6)\n\n# This does not work\ndf |> \n  fsubset(ch == fct & id1 == 6)\n\n# This through error\ndf |> \n  fsubset(ch == get(fct) & id1 == 6) |> \n  try()\n\n# This works\ndf |> \n  fsubset(ch == get(\"fct\", envir = -2) & id1 == 6) \n\n# NOTE: is there a better way?\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt[ch == \"A\" & id1 == 6]\n\ndt[ch == x & id1 == 6]\n\ndt[ch ==ch & id1 == 6]\n\n# this does not work\ndt[ch == fct & id1 == 6]\n\n\ndt[ch == eval(fct) & id1 == 6]\n\n# These work but they are  verbose\ndt[ch == get(\"fct\", envir = parent.frame()) & id1 == 6]\ndt[ch == get(\"fct\", envir = -2) & id1 == 6]\n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntb |> \n  filter(ch == \"A\" & id1 == 6)\n\ntb |> \n  filter(ch == x & id1 == 6)\n\ntb |> \n  filter(ch == ch & id1 == 6)\n\n# does not work\ntb |> \n  filter(ch == fct & id1 == 6)\n\n# works really well\ntb |> \n  filter(ch == !!fct & id1 == 6)\n```\n:::\n\n:::\n\n#### Filter unique rows \n\n::: panel-tabset\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing duplicate rows based on the values of one or more columns \n```\n:::\n\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove duplicate rows\ndf |>\n  funique()\n\n# Keeps only one row per unique value in id2\ndf |>\n  funique(cols = \"int\") # selecting column by col name \ndf |>\n  funique(cols = 6)     # selecting column by indices\ndf |>\n  funique(cols = names(df) %in% \"int\") # with logical condition\n```\n:::\n\n\n## data.table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n # Remove duplicate rows\ndt |>\n  unique()\n\n# Keeps only one row per unique value in id2\ndt |>\n  unique(by = \"id2\")  \n```\n:::\n\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove duplicate rows\ntb |>\n  distinct()\n\n# Keeps only one row per unique id1\ntb |> distinct(id1, .keep_all = TRUE) # keep all col\n```\n:::\n\n:::\n\n#### Discard rows with missing values\n::: panel-tabset\n\n## collapse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ndf |>\n  na_omit()\n\n# Discard rows with NA value for selected col\ndf |>\n  na_omit(cols = \"ch\")\n\n# More flexible options:\n# Remove rows where more than 50% of values are missing\ndf |>\n  na_omit(prop = 0.5)\n```\n:::\n\n\n\n## data.table\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ndt |>\n  na_omit()\n\n# Discard rows with NA value for selected col\ndt <- dt[!is.na(ch)]\n```\n:::\n\n\n\n## tidyverse\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discard rows with any NA value\ntb |>\n  tidyr::drop_na()\n\n# Discard rows with NA value for selected col\ntb |> \n  tidyr::drop_na(ch)\n```\n:::\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}