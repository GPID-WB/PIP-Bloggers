---
title: "Collapse Cheat sheet"
description: "Syntax translation from dplyr and data.tablen to collapse"
author: "PIP Technical team"
date: "03/13/2025"
categories: [collapse, data.table, dplyr, efficiency]
format:
  html:
    toc: true
editor_options: 
  chunk_output_type: console
execute:
  output: false
---

## Introduction

This post is inpired in the Atreba's blog: [A data.table and dplyr tour](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/). The objective of this post is to complement Atreba's one with the syntax of the [`{collapse}`](https://sebkrantz.github.io/collapse/) R package.

## Basic understanding of the three packages

### dplyr

blach

### data.table

blah

### collapse

blah

## Data

```{r}
#| echo: true
#| results: false
#| message: false
#| output: false
#| label: setup
#| warning: false

library(dplyr)
library(data.table)
library(collapse)

```

```{r}
#| label: data
#| cache: true
set.seed(42)

# Number of rows
n <- 10000

# # Generate fake data
# df <- data.frame(
#   id1 = 1:n,  # Unique ID
#   id2 = sample(1:500, n, replace = TRUE),  # Repeating ID
#   dt = seq.Date(from = as.Date("2023-01-01"), by = "day", length.out = n),  # Dates
#   tm = format(seq.POSIXt(from = as.POSIXct("2023-01-01 00:00:00"), 
#                          by = "hour", length.out = n), "%H:%M:%S"),  # Time
#   ch = sample(c("A", "B", "C", "D"), n, replace = TRUE),  # Character
#   int = sample(1:100, n, replace = TRUE),  # Integer
#   log = sample(c(TRUE, FALSE), n, replace = TRUE),  # Logical
#   realf = runif(n, 1, 100),  # Real (float),
#   reald = runif(n),  # Real ,
#   fct = factor(sample(c("X", "Y", "Z"), n, replace = TRUE))  # Factor
# )

set.seed(42)

# Number of rows
n <- 10000

# Generate fake data with some NAs
df <- data.frame(
  id1 = 1:n,  # Unique ID
  id2 = sample(1:500, n, replace = TRUE),  # Repeating ID
  dt = sample(c(seq.Date(from = as.Date("2023-01-01"), by = "day", length.out = n), NA), n, replace = TRUE),  # Dates with NAs
  tm = sample(c(format(seq.POSIXt(from = as.POSIXct("2023-01-01 00:00:00"), 
                                  by = "hour", length.out = n), "%H:%M:%S"), NA), n, replace = TRUE),  # Time with NAs
  ch = sample(c("A", "B", "C", "D", NA), n, replace = TRUE, prob = c(0.24, 0.24, 0.24, 0.24, 0.04)),  # Character with some NAs
  int = sample(c(1:100, NA), n, replace = TRUE),  # Integer with some NAs
  log = sample(c(TRUE, FALSE, NA), n, replace = TRUE, prob = c(0.49, 0.49, 0.02)),  # Logical with some NAs
  realf = sample(c(runif(n, 1, 100), NA), n, replace = TRUE),  # Real (float) with some NAs
  reald = sample(c(runif(n), NA), n, replace = TRUE),  # Real with some NAs
  fct = factor(sample(c("X", "Y", "Z", NA), n, replace = TRUE, prob = c(0.32, 0.32, 0.32, 0.04)))  # Factor with some NAs
)

# Print summary to check distribution of NAs
summary(df)


# Ensure uniqueness
df <- unique(df, by = c("id1", "id2"))
dt <- setDT(df)
tb <- as_tibble(df)

```

## Basic use

### Filtering rows

#### Filter rows using indices

::: panel-tabset
## collapse

```{r}

# super efficient
df |> 
  ss(2:5)

# efficient
df |> 
  fsubset(2:5)

```

## data.table

```{r}
dt[2:5]
```

## dplyr

```{r}
tb |> 
  slice(2:5)

# or using index like any data.frame
tb[2:5,]

# you need to add the comma. Otherwise, you get a different result
tb[2:5]

```
:::

#### Discard rows using negative indices

::: panel-tabset
## collapse

```{r}

df |> 
  ss(-c(2:5)) |> 
  head(4)

df |> 
  ss(-c(2:5)) |> 
  head(4)

```

## data.table

```{r}
dt[!2:5] |> 
  head(4)
```

## dplyr

```{r}
tb |> 
  slice(-(2:5)) |> 
  head(4)

```
:::

#### Filter rows using conditions

::: panel-tabset
```{r}
# using named objects to filter data
ch  <- "A" # data has this as variable name
fct <- "A" # data has this as variable name
x  <- "A"
```

## collapse

```{r}
df |> 
  fsubset(ch == "A" & id1 == 6)

df |> 
  fsubset(ch == x & id1 == 6)

# This works
df |> 
  fsubset(ch == ch & id1 == 6)

# This does not work
df |> 
  fsubset(ch == fct & id1 == 6)

# This through error
df |> 
  fsubset(ch == get(fct) & id1 == 6) |> 
  try()

# This works
df |> 
  fsubset(ch == get("fct", envir = -2) & id1 == 6) 

# NOTE: is there a better way?

```

## data.table

```{r}
dt[ch == "A" & id1 == 6]

dt[ch == x & id1 == 6]

dt[ch ==ch & id1 == 6]

# this does not work
dt[ch == fct & id1 == 6]


dt[ch == eval(fct) & id1 == 6]

# These work but they are  verbose
dt[ch == get("fct", envir = parent.frame()) & id1 == 6]
dt[ch == get("fct", envir = -2) & id1 == 6]


```

## dplyr

```{r}
tb |> 
  filter(ch == "A" & id1 == 6)

tb |> 
  filter(ch == x & id1 == 6)

tb |> 
  filter(ch == ch & id1 == 6)

# does not work
tb |> 
  filter(ch == fct & id1 == 6)

# works really well
tb |> 
  filter(ch == !!fct & id1 == 6)

```
:::

#### Filter unique rows 

::: panel-tabset
```{r}
# Removing duplicate rows based on the values of one or more columns 
```

## collapse

```{r}

# Remove duplicate rows
df |>
  funique()

# Keeps only one row per unique value in id2
df |>
  funique(cols = "int") # selecting column by col name 
df |>
  funique(cols = 6)     # selecting column by indices
df |>
  funique(cols = names(df) %in% "int") # with logical condition
```

## data.table

```{r}
 
 # Remove duplicate rows
dt |>
  unique()

# Keeps only one row per unique value in id2
dt |>
  unique(by = "id2")  
```

## dplyr

```{r}

# Remove duplicate rows
tb |>
  distinct()

# Keeps only one row per unique id1
tb |> distinct(id1, .keep_all = TRUE) # keep all col
```
:::

#### Discard rows with missing values
::: panel-tabset

## collapse

```{r}

# Discard rows with any NA value
df |>
  na_omit()

# Discard rows with NA value for selected col
df |>
  na_omit(cols = "ch")

# More flexible options:
# Remove rows where more than 50% of values are missing
df |>
  na_omit(prop = 0.5)

```


## data.table
```{r}

# Discard rows with any NA value
dt |>
  na_omit()

# Discard rows with NA value for selected col
dt <- dt[!is.na(ch)]

```


## tidyverse
```{r}

# Discard rows with any NA value
tb |>
  tidyr::drop_na()

# Discard rows with NA value for selected col
tb |> 
  tidyr::drop_na(ch)

```
:::

#### Other filters: slice options

::: panel-tabset

## collapse

```{r eval = FALSE}

df |>
  fslice(n = 3)                 # First 3 rows
df |>
  fslice(n   = 3, 
         how = "last")          # Last 3 rows
df |>
  fslice(n = 0.1)               # Fraction of rows: first 10% of rows

fslice(n        = 3, 
       how      = "min", 
       order.by = int)          # 3 obs with lowest int

# TODO: add fslicev()

```


## data.table

```{r}

# Frist 3 rows
dt[1:3, ]   # First 3 rows, all columns


# Last 3 rows
dt[(.N-2):.N]  # .N gives the total number of rows

# Fraction of rows: first 10% of rows
dt[1:(.N * 0.1)]


# 3 obs with lowest int
dt[order(int)][1:3]
 
```


## dplyr

```{r}

# First 3 rows
tb |>
  slice_head(n = 3)

# Last 3 rows
tb |>
  slice_tail(n = 3)

# Fraction of rows: first 10% of rows
tb |>
  slice_head(prop = 0.1)

# 3 obs with lowest int
tb |>
  slice_min(order_by = int, 
            n        = 3) # all rows

tb |>
 slice_min(order_by = int, 
           n        = 3, 
           with_ties = FALSE) 

```
:::

### Sort rows

#### Sort rows by column(s)

::: panel-tabset

## collapse

```{r}
df |>
  roworder(id1)  

df |>
  roworder(-id2)      # Sort by decreasing order of id2

df |>
  roworder(id1, -id2) # Sort by multiple cols 

```


## data.table

```{r}

dt[order(id2)]    # This makes a copy

setorder(dt, id2) # To modify by reference  

dt[order(-id2)]   # Sort by decreasing order

dt[order(id1, -id2)] # Sort by multiple cols 

```

## dplyr

```{r}

tb |>
  arrange(id2)

tb |>
  arrange(desc(id2)) # Sort by decreasing order

# Sort by multiple cols 
df |>
   arrange(id1, desc(id2))

```

::: 

### Select columns
