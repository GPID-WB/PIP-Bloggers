[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What‚Äôs new in PIP?",
    "section": "",
    "text": "Collapse Cheat sheet\n\n\n\n\n\n\ncollapse\n\n\ndata.table\n\n\ndplyr\n\n\nefficiency\n\n\n\nSyntax translation from dplyr and data.tablen to collapse\n\n\n\n\n\nMar 13, 2025\n\n\nPIP Technical team\n\n\n\n\n\n\n\n\n\n\n\n\nException Handling\n\n\n\n\n\n\nErrors\n\n\nWarnings\n\n\n\nExample for pipdata\n\n\n\n\n\nFeb 13, 2025\n\n\nDiana C. Garcia\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#load-libraries-and-functions",
    "href": "index.html#load-libraries-and-functions",
    "title": "First Blog",
    "section": "",
    "text": "First, these are the main libraries I used.\n# Load libraries\nlibrary(metapip)\nlibrary(data.table)\nHowever, make sure to have installed the following packages as well: cli and rlang .\nThe following is the example of the function I need to be ‚Äúhandle‚Äù with tryCatch . This function tries to check if there are duplicates in dt according to some keyVar and if there are duplicates it could abort and exit or continue without exiting. The function has another two parameters to decide the following:\n1. log_err if we want the error to be included in a error-report log ( TRUE and FALSE)\n2. skip_err if we want the error to be skipped ( TRUE and FALSE)\n# Function to handle duplicated observations in pfw\nunq_pfw &lt;- function(dt,\n                    keyVar,\n                    log_err = TRUE,\n                    skip_err = TRUE) {\n\n  tryCatch(\n\n    expr = {\n\n      if(uniqueN(dt, by = keyVar) != nrow(dt)){\n\n        dt_d &lt;- dt[duplicated(dt, by = keyVar)]\n        n_rep &lt;- nrow(dt_d)\n\n        cli::cli_abort(message = \"There {?is/are} {n_rep} duplicates in `pfw`\",\n                       class = c(\"dup_pfw\", \"piperr\"),\n                       log = log_err,\n                       skip = skip_err,\n                       link =  unique(dt_d$link),\n                       call = sys.call())\n      }\n\n    },\n\n    dup_pfw = function(cnd){\n\n      if(cnd$log){ # Log the error\n\n        add_log(cnd)\n\n      }\n\n      if(!cnd$skip){ # Abort if you don't want to skip, but after logging\n\n        cli::cli_abort(cnd$message, call = cnd$call)\n\n      }\n\n    },\n\n    finally = {\n\n      dt &lt;- unique(dt, by = keyVar) # eliminate duplicates\n\n    }\n\n  )\n\n\n  return(dt)\n\n}\nIf you run the lines within expr ={ } , this will probably crash and an error about duplicates will be shown. However, what I want is to first record this error on a log, and then decide if to skip the error or not, and get a clean dataset. That is why we need tryCatch . As you can see within the finally section, I also included a line that eliminates the duplicates and returns the new ‚Äúclean‚Äù dataset. This is because I am going to ‚Äúhandle‚Äù the abort actions with tryCatch and after this, R will ‚Äúfinally‚Äù run these lines and give us the clean output we need (if we do not want to abort).\nNow let me explain the steps within the tryCatch . First, you might be wondering what are the parameters within cli::cli_abort() . I assume message is straightforward. However, class might be the most important. The class we give to this specific error, or condition, will be what makes it identifiable on our tryCatch . Since we gave a new class to the error called dup_pfw , the function tryCatch, instead of aborting and exiting the code when the error is found, will run the code within dup_pfw = function(cnd){ } instead. The parameter cnd then carries all the information we gave within cil::cli_abort ; the class , the log/skip actions, and the identifiers of the duplicates link .\nImportant: The parameters log and skip within cil::cli_abort are my tools to decide how to handle this error and these are totally made up by me for this specific function. You can create any parameter you want within cli::abort() and this will carry on within the handler. For example, I created the parameter link which will carry the identifiers of those duplicated observations. These are needed for the error-report log.\nTalking about the log, before you run the code below, please load the following function add_log . This function will load some concatenated text on the file log.txt saved in your working directory and it is used within the handler.\n# Function for logging\nadd_log &lt;- function(cnd) {\n\n  cat(\n    \"[\", class(cnd)[[1]], \"-\", class(cnd)[[2]], \"] \",\n    cnd$message,\" for \",\n    cnd$link, \"\\n\", sep = \"\",\n    file = \"log.txt\", append = TRUE\n  )\n\n}"
  },
  {
    "objectID": "index.html#load-data-and-run-code",
    "href": "index.html#load-data-and-run-code",
    "title": "First Blog",
    "section": "",
    "text": "The data used for this example can be loaded with pipload and represents the auxiliary Price Frame Work, or pfw . Since I needed it to run over the error at some point, I also create another data frame with some duplicates, pfw_d .\n# Load data\npfw_t &lt;- pip_load_aux(\"pfw\")\n\npfw_d &lt;- rbind(pfw_t, pfw_t[rep(1, 5), ]) # Duplicate some rows from one country\nNow, we will run the function and this should not give you any errors because the default value of skip_err = TRUE .\n# Run tryCatch for unq_pwf function\nkeyVar &lt;- c(\"country_code\", \"surveyid_year\", \"survey_acronym\")\n\npfw &lt;- unq_pfw(pfw_d, keyVar)\nIf the error was handled and skipped correctly (default parameters), the answer to the following code should give you TRUE and you will find a log.txt file with the new record of these error.\n# Test\n\nuniqueN(pfw, by = keyVar) == nrow(pfw)\nHowever, if you run the function without skipping the error, the abort function will come into action:\n# Run tryCatch for unq_pwf function without skipping error\n\npfw &lt;- unq_pfw(pfw_d, keyVar, skip_err = FALSE)\nLet me know if that is not the case, or if you have any questions about the example! Happy to talk about it and learn together üôÇ"
  },
  {
    "objectID": "index.html#sources",
    "href": "index.html#sources",
    "title": "First Blog",
    "section": "",
    "text": "A few websites I reviewed to learned more about this:\n\nhttps://adv-r.hadley.nz/conditions.html#conditions\nhttps://medium.com/number-around-us/catch-me-if-you-can-exception-handling-in-r-2e0f6c473a28\nhttps://cnuge.github.io/post/trycatch/\nhttps://aryoda.github.io/tutorials/tryCatchLog/tryCatchLog-intro-slides.html#/ (still reviewing it)"
  },
  {
    "objectID": "index.html#work-in-progress",
    "href": "index.html#work-in-progress",
    "title": "First Blog",
    "section": "",
    "text": "A few things I am still figuring/working out are:\n\nI still have to format the add_log function to allowed for more than one character on the cnd$link value, or to make it more general so it can be used in other handlers."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Cool content about the development of PIP packages"
  },
  {
    "objectID": "posts/Excp_Hndl/index.html",
    "href": "posts/Excp_Hndl/index.html",
    "title": "Exception Handling",
    "section": "",
    "text": "The following is an example of how to use exception handling in R for our packages. In particular, I focus on using tryCatch . This is an example still in the making (so I will probably updated once I understand better the topic and I have created a final version for pipdata ), but for now, you all can already give it a try."
  },
  {
    "objectID": "posts/Excp_Hndl/index.html#load-libraries-and-functions",
    "href": "posts/Excp_Hndl/index.html#load-libraries-and-functions",
    "title": "Exception Handling",
    "section": "Load libraries and functions",
    "text": "Load libraries and functions\nFirst, these are the main libraries I used.\n# Load libraries library(metapip) library(data.table)\nHowever, make sure to have installed the following packages as well: cli and rlang .\nThe following is the example of the function I need to be ‚Äúhandle‚Äù with tryCatch . This function tries to check if there are duplicates in dt according to some keyVar and if there are duplicates it could abort and exit or continue without exiting. The function has another two parameters to decide the following:\n1. log_err if we want the error to be included in a error-report log ( TRUE and FALSE)\n2. skip_err if we want the error to be skipped ( TRUE and FALSE)\n# Function to handle duplicated observations in pfw unq_pfw &lt;- function(dt,                     keyVar,                     log_err = TRUE,                     skip_err = TRUE) {    tryCatch(      expr = {        if(uniqueN(dt, by = keyVar) != nrow(dt)){          dt_d &lt;- dt[duplicated(dt, by = keyVar)]         n_rep &lt;- nrow(dt_d)          cli::cli_abort(message = \"There {?is/are} {n_rep} duplicates in `pfw`\",                        class = c(\"dup_pfw\", \"piperr\"),                        log = log_err,                        skip = skip_err,                        link =  unique(dt_d$link),                        call = sys.call())       }      },      dup_pfw = function(cnd){        if(cnd$log){ # Log the error          add_log(cnd)        }        if(!cnd$skip){ # Abort if you don't want to skip, but after logging          cli::cli_abort(cnd$message, call = cnd$call)        }      },      finally = {        dt &lt;- unique(dt, by = keyVar) # eliminate duplicates      }    )     return(dt)  }\nIf you run the lines within expr ={ } , this will probably crash and an error about duplicates will be shown. However, what I want is to first record this error on a log, and then decide if to skip the error or not, and get a clean dataset. That is why we need tryCatch . As you can see within the finally section, I also included a line that eliminates the duplicates and returns the new ‚Äúclean‚Äù dataset. This is because I am going to ‚Äúhandle‚Äù the abort actions with tryCatch and after this, R will ‚Äúfinally‚Äù run these lines and give us the clean output we need (if we do not want to abort).\nNow let me explain the steps within the tryCatch . First, you might be wondering what are the parameters within cli::cli_abort() . I assume message is straightforward. However, class might be the most important. The class we give to this specific error, or condition, will be what makes it identifiable on our tryCatch . Since we gave a new class to the error called dup_pfw , the function tryCatch, instead of aborting and exiting the code when the error is found, will run the code within dup_pfw = function(cnd){ } instead. The parameter cnd then carries all the information we gave within cil::cli_abort ; the class , the log/skip actions, and the identifiers of the duplicates link .\nImportant: The parameters log and skip within cil::cli_abort are my tools to decide how to handle this error and these are totally made up by me for this specific function. You can create any parameter you want within cli::abort() and this will carry on within the handler. For example, I created the parameter link which will carry the identifiers of those duplicated observations. These are needed for the error-report log.\nTalking about the log, before you run the code below, please load the following function add_log . This function will load some concatenated text on the file log.txt saved in your working directory and it is used within the handler.\n# Function for logging add_log &lt;- function(cnd) {    cat(     \"[\", class(cnd)[[1]], \"-\", class(cnd)[[2]], \"] \",     cnd$message,\" for \",     cnd$link, \"\\n\", sep = \"\",     file = \"log.txt\", append = TRUE   )  }"
  },
  {
    "objectID": "posts/Excp_Hndl/index.html#load-data-and-run-code",
    "href": "posts/Excp_Hndl/index.html#load-data-and-run-code",
    "title": "Exception Handling",
    "section": "Load data and run code",
    "text": "Load data and run code\nThe data used for this example can be loaded with pipload and represents the auxiliary Price Frame Work, or pfw . Since I needed it to run over the error at some point, I also create another data frame with some duplicates, pfw_d .\n# Load data pfw_t &lt;- pip_load_aux(\"pfw\")  pfw_d &lt;- rbind(pfw_t, pfw_t[rep(1, 5), ]) # Duplicate some rows from one country\nNow, we will run the function and this should not give you any errors because the default value of skip_err = TRUE .\n# Run tryCatch for unq_pwf function keyVar &lt;- c(\"country_code\", \"surveyid_year\", \"survey_acronym\")  pfw &lt;- unq_pfw(pfw_d, keyVar)\nIf the error was handled and skipped correctly (default parameters), the answer to the following code should give you TRUE and you will find a log.txt file with the new record of these error.\n# Test  uniqueN(pfw, by = keyVar) == nrow(pfw)\nHowever, if you run the function without skipping the error, the abort function will come into action:\n# Run tryCatch for unq_pwf function without skipping error  pfw &lt;- unq_pfw(pfw_d, keyVar, skip_err = FALSE)\nLet me know if that is not the case, or if you have any questions about the example! Happy to talk about it and learn together üôÇ"
  },
  {
    "objectID": "posts/Excp_Hndl/index.html#sources",
    "href": "posts/Excp_Hndl/index.html#sources",
    "title": "Exception Handling",
    "section": "Sources",
    "text": "Sources\nA few websites I reviewed to learned more about this:\n\nhttps://adv-r.hadley.nz/conditions.html#conditions\nhttps://medium.com/number-around-us/catch-me-if-you-can-exception-handling-in-r-2e0f6c473a28\nhttps://cnuge.github.io/post/trycatch/\nhttps://aryoda.github.io/tutorials/tryCatchLog/tryCatchLog-intro-slides.html#/ (still reviewing it)"
  },
  {
    "objectID": "posts/Excp_Hndl/index.html#work-in-progress",
    "href": "posts/Excp_Hndl/index.html#work-in-progress",
    "title": "Exception Handling",
    "section": "Work in progress‚Ä¶",
    "text": "Work in progress‚Ä¶\nA few things I am still figuring/working out are:\n\nI still have to format the add_log function to allowed for more than one character on the cnd$link value, or to make it more general so it can be used in other handlers."
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html",
    "href": "posts/collapse_cheat_sheet/index.html",
    "title": "Collapse Cheat sheet",
    "section": "",
    "text": "This post is inspired in the Atreba‚Äôs blog: A data.table and dplyr tour. The objective of this post is to complement Atreba‚Äôs one with the syntax of the {collapse} R package."
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#introduction",
    "href": "posts/collapse_cheat_sheet/index.html#introduction",
    "title": "Collapse Cheat sheet",
    "section": "",
    "text": "This post is inspired in the Atreba‚Äôs blog: A data.table and dplyr tour. The objective of this post is to complement Atreba‚Äôs one with the syntax of the {collapse} R package."
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#basic-understanding-of-the-three-packages",
    "href": "posts/collapse_cheat_sheet/index.html#basic-understanding-of-the-three-packages",
    "title": "Collapse Cheat sheet",
    "section": "Basic understanding of the three packages",
    "text": "Basic understanding of the three packages\n\ndplyr\nA grammar of data manipulation in R which provides a consistent set of verbs to help you solve the most common data manipulation challenges. It is part of the tidyverse universe. Click here for more information..\n\n\ndata.table\nA syntax to operate data manipulation operations, such as subset, group, update, join, etc. It reduces programming and compute time tremendously. Click here for more information.\n\n\ncollapse\nA large C/C++ based package for data transformation and statistical computing in R. It aims to facilitate complex data transformations, explorations and computing tasks in R, while making code fast, flexible, parsimonious and programmer friendly. Click here for more information."
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#data",
    "href": "posts/collapse_cheat_sheet/index.html#data",
    "title": "Collapse Cheat sheet",
    "section": "Data",
<<<<<<< HEAD
    "text": "Data\n\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(collapse)\nlibrary(tidyverse)\n\n\nset.seed(42)\n\n# Number of rows\nn &lt;- 10000\n\n# # Generate fake data\n# df &lt;- data.frame(\n#   id1 = 1:n,  # Unique ID\n#   id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n#   dt = seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n),  # Dates\n#   tm = format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n#                          by = \"hour\", length.out = n), \"%H:%M:%S\"),  # Time\n#   ch = sample(c(\"A\", \"B\", \"C\", \"D\"), n, replace = TRUE),  # Character\n#   int = sample(1:100, n, replace = TRUE),  # Integer\n#   log = sample(c(TRUE, FALSE), n, replace = TRUE),  # Logical\n#   realf = runif(n, 1, 100),  # Real (float),\n#   reald = runif(n),  # Real ,\n#   fct = factor(sample(c(\"X\", \"Y\", \"Z\"), n, replace = TRUE))  # Factor\n# )\n\nset.seed(42)\n\n# Number of rows\nn &lt;- 10000\n\n# Generate fake data with some NAs\ndf &lt;- data.frame(\n  id1 = 1:n,  # Unique ID\n  id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n  dt = sample(c(seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n), NA), n, replace = TRUE),  # Dates with NAs\n  tm = sample(c(format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n                                  by = \"hour\", length.out = n), \"%H:%M:%S\"), NA), n, replace = TRUE),  # Time with NAs\n  ch = sample(c(\"A\", \"B\", \"C\", \"D\", NA), n, replace = TRUE, prob = c(0.24, 0.24, 0.24, 0.24, 0.04)),  # Character with some NAs\n  int = sample(c(1:100, NA), n, replace = TRUE),  # Integer with some NAs\n  log = sample(c(TRUE, FALSE, NA), n, replace = TRUE, prob = c(0.49, 0.49, 0.02)),  # Logical with some NAs\n  realf = sample(c(runif(n, 1, 100), NA), n, replace = TRUE),  # Real (float) with some NAs\n  reald = sample(c(runif(n), NA), n, replace = TRUE),  # Real with some NAs\n  fct = factor(sample(c(\"X\", \"Y\", \"Z\", NA), n, replace = TRUE, prob = c(0.32, 0.32, 0.32, 0.04)))  # Factor with some NAs\n)\n\n# Print summary to check distribution of NAs\nsummary(df)\n\n\n# Ensure uniqueness\ndf &lt;- unique(df, by = c(\"id1\", \"id2\"))\ndt &lt;- setDT(df)\ntb &lt;- as_tibble(df)"
=======
    "text": "Data\n\nset.seed(42)\n\n# Number of rows\nn &lt;- 10000\n\n# Generate fake data\ndf &lt;- data.frame(\n  id1 = 1:n,  # Unique ID\n  id2 = sample(1:500, n, replace = TRUE),  # Repeating ID\n  dt = seq.Date(from = as.Date(\"2023-01-01\"), by = \"day\", length.out = n),  # Dates\n  tm = format(seq.POSIXt(from = as.POSIXct(\"2023-01-01 00:00:00\"), \n                         by = \"hour\", length.out = n), \"%H:%M:%S\"),  # Time\n  ch = sample(c(\"A\", \"B\", \"C\", \"D\"), n, replace = TRUE),  # Character\n  int = sample(1:100, n, replace = TRUE),  # Integer\n  log = sample(c(TRUE, FALSE), n, replace = TRUE),  # Logical\n  realf = runif(n, 1, 100),  # Real (float),\n  reald = runif(n),  # Real ,\n  fct = factor(sample(c(\"X\", \"Y\", \"Z\"), n, replace = TRUE))  # Factor\n)\n\n# Ensure uniqueness\ndf &lt;- unique(df, by = c(\"id1\", \"id2\"))\ndt &lt;- copy(setDT(df))\ntb &lt;- as_tibble(df)"
>>>>>>> collapse_cheat_sheet
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#basic-use",
    "href": "posts/collapse_cheat_sheet/index.html#basic-use",
    "title": "Collapse Cheat sheet",
    "section": "Basic use",
<<<<<<< HEAD
    "text": "Basic use\n\nFiltering rows\n\nFilter rows using indices\n\ncollapsedata.tabledplyr\n\n\n\n# super efficient\ndf |&gt; \n  ss(2:5)\n\n# efficient\ndf |&gt; \n  fsubset(2:5)\n\n\n\n\ndt[2:5]\n\n\n\n\ntb |&gt; \n  slice(2:5)\n\n# or using index like any data.frame\ntb[2:5,]\n\n# you need to add the comma. Otherwise, you get a different result\ntb[2:5]\n\n\n\n\n\n\nDiscard rows using negative indices\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  ss(-c(2:5)) |&gt; \n  head(4)\n\ndf |&gt; \n  ss(-c(2:5)) |&gt; \n  head(4)\n\n\n\n\ndt[!2:5] |&gt; \n  head(4)\n\n\n\n\ntb |&gt; \n  slice(-(2:5)) |&gt; \n  head(4)\n\n\n\n\n\n\nFilter rows using conditions\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  fsubset(ch == \"A\" & id1 == 6)\n\ndf |&gt; \n  fsubset(ch == x & id1 == 6)\n\n# This works\ndf |&gt; \n  fsubset(ch == ch & id1 == 6)\n\n# This does not work\ndf |&gt; \n  fsubset(ch == fct & id1 == 6)\n\n# This through error\ndf |&gt; \n  fsubset(ch == get(fct) & id1 == 6) |&gt; \n  try()\n\n# This works\ndf |&gt; \n  fsubset(ch == get(\"fct\", envir = -2) & id1 == 6) \n\n# NOTE: is there a better way?\n\n\n\n\ndt[ch == \"A\" & id1 == 6]\n\ndt[ch == x & id1 == 6]\n\ndt[ch ==ch & id1 == 6]\n\n# this does not work\ndt[ch == fct & id1 == 6]\n\n\ndt[ch == eval(fct) & id1 == 6]\n\n# These work but they are  verbose\ndt[ch == get(\"fct\", envir = parent.frame()) & id1 == 6]\ndt[ch == get(\"fct\", envir = -2) & id1 == 6]\n\n\n\n\ntb |&gt; \n  filter(ch == \"A\" & id1 == 6)\n\ntb |&gt; \n  filter(ch == x & id1 == 6)\n\ntb |&gt; \n  filter(ch == ch & id1 == 6)\n\n# does not work\ntb |&gt; \n  filter(ch == fct & id1 == 6)\n\n# works really well\ntb |&gt; \n  filter(ch == !!fct & id1 == 6)\n\n\n\n\n\n\nFilter unique rows\n\ncollapsedata.tabledplyr\n\n\n\n# Remove duplicate rows\ndf |&gt;\n  funique()\n\n# Keeps only one row per unique value in id2\ndf |&gt;\n  funique(cols = \"int\") # selecting column by col name \ndf |&gt;\n  funique(cols = 6)     # selecting column by indices\ndf |&gt;\n  funique(cols = names(df) %in% \"int\") # with logical condition\n\n\n\n\n # Remove duplicate rows\ndt |&gt;\n  unique()\n\n# Keeps only one row per unique value in id2\ndt |&gt;\n  unique(by = \"id2\")  \n\n\n\n\n# Remove duplicate rows\ntb |&gt;\n  distinct()\n\n# Keeps only one row per unique id1\ntb |&gt; distinct(id1, .keep_all = TRUE) # keep all col\n\n\n\n\n\n\nDiscard rows with missing values\n\ncollapsedata.tabletidyverse\n\n\n\n# Discard rows with any NA value\ndf |&gt;\n  na_omit()\n\n# Discard rows with NA value for selected col\ndf |&gt;\n  na_omit(cols = \"ch\")\n\n# More flexible options:\n# Remove rows where more than 50% of values are missing\ndf |&gt;\n  na_omit(prop = 0.5)\n\n\n\n\n# Discard rows with any NA value\ndt |&gt;\n  na_omit()\n\n# Discard rows with NA value for selected col\ndt &lt;- dt[!is.na(ch)]\n\n\n\n\n# Discard rows with any NA value\ntb |&gt;\n  tidyr::drop_na()\n\n# Discard rows with NA value for selected col\ntb |&gt; \n  tidyr::drop_na(ch)\n\n\n\n\n\n\nOther filters: slice options\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt;\n  fslice(n = 3)                 # First 3 rows\ndf |&gt;\n  fslice(n   = 3, \n         how = \"last\")          # Last 3 rows\ndf |&gt;\n  fslice(n = 0.1)               # Fraction of rows: first 10% of rows\n\nfslice(n        = 3, \n       how      = \"min\", \n       order.by = int)          # 3 obs with lowest int\n\n# TODO: add fslicev()\n\n\n\n\n# Frist 3 rows\ndt[1:3, ]   # First 3 rows, all columns\n\n\n# Last 3 rows\ndt[(.N-2):.N]  # .N gives the total number of rows\n\n# Fraction of rows: first 10% of rows\ndt[1:(.N * 0.1)]\n\n\n# 3 obs with lowest int\ndt[order(int)][1:3]\n\n\n\n\n# First 3 rows\ntb |&gt;\n  slice_head(n = 3)\n\n# Last 3 rows\ntb |&gt;\n  slice_tail(n = 3)\n\n# Fraction of rows: first 10% of rows\ntb |&gt;\n  slice_head(prop = 0.1)\n\n# 3 obs with lowest int\ntb |&gt;\n  slice_min(order_by = int, \n            n        = 3) # all rows\n\ntb |&gt;\n slice_min(order_by = int, \n           n        = 3, \n           with_ties = FALSE) \n\n\n\n\n\n\n\nSort rows\n\nSort rows by column(s)\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt;\n  roworder(id1)  \n\ndf |&gt;\n  roworder(-id2)      # Sort by decreasing order of id2\n\ndf |&gt;\n  roworder(id1, -id2) # Sort by multiple cols \n\n\n\n\ndt[order(id2)]    # This makes a copy\n\nsetorder(dt, id2) # To modify by reference  \n\ndt[order(-id2)]   # Sort by decreasing order\n\ndt[order(id1, -id2)] # Sort by multiple cols \n\n\n\n\ntb |&gt;\n  arrange(id2)\n\ntb |&gt;\n  arrange(desc(id2)) # Sort by decreasing order\n\n# Sort by multiple cols \ndf |&gt;\n   arrange(id1, desc(id2))\n\n\n\n\n\n\n\nSelect columns\n\nSelect one or more columns\n\ncollapsedata.tabledplyr\n\n\n\n## Select one column   ####\n# _________________________ \n\n# by index\ndf |&gt;\n  fselect(2)\n\ndf |&gt;\n  slt(2) # shorthand for fselect\n\n# by name\n\ndf |&gt;\n  fselect(id2)  # returns a dataframe \n\n## Select multiple columns ####\n# _____________________________ \n\ndf |&gt;\n  fselect(id1, id2, fct)\n\ndf |&gt;\n  fselect(id1, ch:fct)\n\n\n\n\n## Select one column   ####\n# _________________________ \n\n# by index\ndt[[3]]  # returns a vector\ndt[, 3]  # returns a data.table\n\n# by name\ndt[, list(id2)] # returns a data.table\ndt[, .(id2)]    # returns a data.table (. is an alias for list)\ndt[, \"id2\"]     # returns a data.table\ndt[, id2]       # returns a vector\ndt[[\"id2\"]]     # returns a vector\n\n## Select multiple columns ####\n# _____________________________ \n\ndt[, .(id1, id2, int)]\ndt[, list(id1, id2, int)]\ndt[, id2:int] # select columns between id2 and int\n\n\n\n\n## Select one column   ####\n# _________________________ \n\ntb |&gt;\n  select(id2)               # returns a tibble\n\npull(tb, id2, name = ch)    # returns a (named) vector\ntb[, \"id2\"]                 # returns a tibble\ntb[[\"id2\"]]                 # returns a vector\n\n## Select multiple columns ####\n# _____________________________ \n\ndf |&gt;\n  select(id1, id2, ch)\ndf |&gt;\n  select(id1, ch:fct)\n\n\n\n\n\n\nExclude columns\n\ncollapsedata.tabledplyr\n\n\n\n# Exclude columns by column names \ndf |&gt;\n  fselect(-dt, -tm)\n\n# Using a character vector \ncols &lt;- c(\"dt\", \"tm\")\n\ndf |&gt;\n  fselect(-cols)  # does not work \n\nError in -cols: invalid argument to unary operator\n\ndf |&gt;\n  fselect(!cols) # does not work \n\nError in !cols: invalid argument type\n\n# what is a better way to do this?\n\n\n\n\n# Exclude columns by column names \ndt[, !c(\"dt\", \"tm\")]\n\n# Using a character vector \ncols &lt;- c(\"dt\", \"tm\")\n\ndt[, ..cols] \n# .. prefix means 'one-level up', as cols is outside the parent environment \n\ndt[, !..cols] # or dt[, -..cols]\n\n\n\n\n# Exclude columns by column names \ntb |&gt;\n  select( -dt, -tm)\n\n# Using a character vector \ncols &lt;- c(\"dt\", \"tm\")\n\ntb |&gt;\n  select(all_of(cols))\n\ntb |&gt;\n  select(-all_of(cols))\n\n\n\n\n\n\nOther selections - not sure it is relevant, to check\n\n\n\nMiscellaneous\n\nRead & write data\n\nWrite\n\ncollapsedata.tabledplyr\n\n\n\n# no specific functions for reading and writing data \n\n\n\n\nfwrite(dt, \n       \"DT.csv\")                # write to csv\n\n\nfwrite(dt, \n       \"DT.txt\", \n       sep = \"\\t\")              # write to a tab-delimited file\n\n\n\n\nreadr::write_csv(tb, \n                 \"tb.csv\")  # write to csv\n\nreadr::write_delim(tb, \n                   \"tb.txt\", \n                   delim = \"\\t\")  # write to a tab-delimited file\n\n\n\n\n\n\nRead\n\ncollapsedata.tabledplyr\n\n\n\n# no specific functions for reading and writing data \n\n\n\n\nfread(\"dt.csv\")   # read csv\n# fread(\"DT.csv\", verbose = TRUE) # full details\n\nfread(\"dt.txt\", sep = \"\\t\") # read tab-delimited file\n\n# Read and rbind several files\nrbindlist(\n  lapply(c(\"dt.csv\", \"dt.csv\"), \n         fread))\n\n\n\n\nreadr::read_csv(\"tb.csv\")  # read csv\n\nreadr::read_delim(\"tb.txt\", \n                  delim = \"\\t\")  # read tab-delimited file\n\n# Read and rbind several files\nc(\"tb.csv\",  \"tb.csv\") |&gt;\n  purrr::map_dfr(readr::read_csv)\n\n\n\n\n\n\n\nReshape data\n\ncollapsedata.tabledplyr\n\n\n\n# ---- Long to Wide ----\nwide_pivot &lt;- pivot(df, \n                    ids    = c(\"id1\", \"id2\", \"dt\"),  # Columns to keep\n                    values = \"int\",              # Column with values\n                    names  = \"ch\",   # Column whose values become new cols\n                    how    = \"wider\")               # Reshape to wide format\n\n# ---- Wide to Long ----\nlong_pivot &lt;- pivot(wide_pivot, \n                    ids    = c(\"id1\", \"id2\", \"dt\"),  \n                    values = NULL,  \n                    names  = list(\"ch\", \"int\"),  \n                    how    = \"longer\")     \n\n\n\n\n# ---- Long to Wide ----\nwide_dt &lt;- dcast(dt, \n                 id1 + id2 + dt ~ ch, \n                 value.var = \"int\")\n\n# ---- Wide to Long ----\nlong_dt &lt;- melt(wide_dt, \n                id.vars       = c(\"id1\", \"id2\", \"dt\"), \n                variable.name = \"ch\", \n                value.name    = \"int\")\n\n\n\n\n# ---- Long to Wide ----\ntb_wide &lt;- tb |&gt;\n  # rm NAs\n  filter(!is.na(ch)) |&gt;\n  pivot_wider(names_from  = ch, \n              values_from = int)\n\n# ---- Wide to Long ----\ntb_long &lt;- tb_wide |&gt;\n  pivot_longer(cols      = c(\"A\", \"D\", \"C\", \"B\"),\n               values_to = \"int\",\n               names_to  = \"ch\")\n\n\n\n\n\n\nData Conversion\nTBD\n\n\nGlobal options affecting package operation - only in {collapse}\nTBD"
=======
    "text": "Basic use\n\nFiltering rows\n\nFilter rows using indices\n\ncollapsedata.tabledplyr\n\n\n\n# super efficient\ndf |&gt; \n  ss(2:5)\n\n# efficient\ndf |&gt; \n  fsubset(2:5)\n\n\n\n\ndt[2:5]\n\n\n\n\ntb |&gt; \n  slice(2:5)\n\n# or using index like any data.frame\ntb[2:5,]\n\n# you need to add the comma. Otherwise, you get a different result\ntb[2:5]\n\n\n\n\n\n\nDiscard rows using negative indices\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  ss(-c(2:5)) |&gt; \n  head(4)\n\ndf |&gt; \n  ss(-c(2:5)) |&gt; \n  head(4)\n\n\n\n\ndt[!2:5] |&gt; \n  head(4)\n\n\n\n\ntb |&gt; \n  slice(-(2:5)) |&gt; \n  head(4)\n\n\n\n\n\n\nFilter rows using conditions\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  fsubset(ch == \"A\" & id1 == 6)\n\ndf |&gt; \n  fsubset(ch == x & id1 == 6)\n\n# This works\ndf |&gt; \n  fsubset(ch == ch & id1 == 6)\n\n# This does not work\ndf |&gt; \n  fsubset(ch == fct & id1 == 6)\n\n# This through error\ndf |&gt; \n  fsubset(ch == get(fct) & id1 == 6) |&gt; \n  try()\n\n# This works\ndf |&gt; \n  fsubset(ch == get(\"fct\", envir = -2) & id1 == 6) \n\n# NOTE: is there a better way?\n\n\n\n\ndt[ch == \"A\" & id1 == 6]\n\ndt[ch == x & id1 == 6]\n\ndt[ch ==ch & id1 == 6]\n\n# this does not work\ndt[ch == fct & id1 == 6]\n\n\ndt[ch == eval(fct) & id1 == 6]\n\n# These work but they are  verbose\ndt[ch == get(\"fct\", envir = parent.frame()) & id1 == 6]\ndt[ch == get(\"fct\", envir = -2) & id1 == 6]\n\n\n\n\ntb |&gt; \n  filter(ch == \"A\" & id1 == 6)\n\ntb |&gt; \n  filter(ch == x & id1 == 6)\n\ntb |&gt; \n  filter(ch == ch & id1 == 6)\n\n# does not work\ntb |&gt; \n  filter(ch == fct & id1 == 6)\n\n# works really well\ntb |&gt; \n  filter(ch == !!fct & id1 == 6)\n\n\n\n\n\n\n\nSummarise data\n\nSummarise columns\n\ncollapsedata.tabledplyr\n\n\n\n# efficient\ndf |&gt;\n  fsummarise(sum_rf = fsum(realf),\n             sd_rd = fsd(reald))\n\n# shorthand\ndf |&gt;\n  smr(sum_rf = fsum(realf),\n      sd_rd = fsd(reald))\n\n\n\n\ndt[, sum(realf)] # returns a vector\n\ndt[, .(sum(realf))] # returns a data.table\n\ndt[, .(sum_rf = sum(realf), # returns a data.table with named columns\n       sd_rd = sd(reald))]\n\n\n\n\nsummarise(tb, sum(realf)) # returns a tibble\n\ntb |&gt; \n  summarise(sum_rf = sum(realf), # returns a tibble\n            sd_rd = sd(reald))\n\n\n\n\n\n\nHelper functions\n\ncollapsedata.tabledplyr\n\n\nThe package includes fsum,fprod, fmedian, fmode, fvar, fsd, fmin,fmax,fnth, ffirst, flast,fnobs, and fndistinct.\n\n\nThe package includes first, last and uniqueN.\n\n\nThe package includes first, last, n, nth, and n_distinct.\n\n\n\n\n\n\nManipulations of columns\n\ncollapsedata.tabledplyr\n\n\n\n # Add one oe several columns (can also use ftransform)\ndf &lt;- df |&gt;\n  fmutate(log_rf = log(realf)) \n\ndf &lt;- df |&gt;\n  fmutate(log_rd = log(reald),\n           sqrt_rd = sqrt(reald))\n\n# Create one column and eliminate others\nfcompute(df, log2_rf = log_rf*2) \n\n # remove columns\ndf &lt;- df |&gt;\n  fselect(-log_rf,-log_rd,-sqrt_rd)\n\n\n\n\n# Add one column\ndt[, log_rf := log(realf)] \n\n# Add several columns\ndt[, ':=' (log_rd = log(reald), \n           sqrt_rd = sqrt(reald))]\n\n# Create one column and eliminate others\ndt[, .(log2_rf = log_rf*2)] \n\n# remove columns\ndt[, c(\"log_rf\", \"log_rd\", \"sqrt_rd\") := NULL] \n\n\n\n\n# Add one or several column\ntb &lt;- tb |&gt; \n  mutate(log_rf = log(realf))\n\ntb &lt;- tb |&gt; \n  mutate(log_rd = log(reald), \n           sqrt_rd = sqrt(reald))\n\n# Create one column and eliminate others\ntransmute(tb, log2_rf = log_rf*2)\n\n# remove columns\ntb &lt;- tb |&gt; \n  select(-log_rf,-log_rd,-sqrt_rd)\n\n\n\n\n\n\nby\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  fgroup_by(ch)|&gt;\n  fsummarise(sumrf = fsum(realf)) # ordered and indexed results\n\n# Assigned column name\n\ndf |&gt; \n  fgroup_by(abc = tolower(ch))|&gt;\n  fsummarise(sumrf = fsum(realf))\n\n# Add a column with number of observations for each group\n\ndf |&gt;\n  fgroup_by(ch)|&gt;\n  fcount(add = TRUE)\n\n\n\n\ndt[, .(sumrf = sum(realf)), by = \"ch\"] # unordered results\n\n# Reordered and indented:\n\ndt[, keyby = ch,\n     .(sumrf = sum(realf))]\n\n# Assigning column name\n\ndt[, keyby = .(abc = tolower(ch)),\n     .(sumrf = sum(realf))]\n\n# Add a column with number of observations for each group\n\ndt[, n := .N, by = ch][]\ndt[, n := NULL] # remove for consistency\n\n\n\n\ntb |&gt; \n  group_by(ch)|&gt;\n  summarise(sumrf = sum(realf)) # ordered results\n\n# Assigned column name\n\ntb |&gt; \n  group_by(abc = tolower(ch))|&gt;\n  summarise(sumrf = sum(realf))\n\n# Add a column with number of observations for each group\n\ntb |&gt;\n  group_by(ch)|&gt;\n  add_tally()\n\n# or...\n\nadd_count(tb, ch)"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#load-libraries",
    "href": "posts/collapse_cheat_sheet/index.html#load-libraries",
    "title": "Collapse Cheat sheet",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(collapse)"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#other-useful-functions-in-collapse",
    "href": "posts/collapse_cheat_sheet/index.html#other-useful-functions-in-collapse",
    "title": "Collapse Cheat sheet",
    "section": "Other useful functions in collapse",
    "text": "Other useful functions in collapse\n\n# quick summary (From STATA summarize and xtsummarize)\n\nqsu(df, cols = c(\"realf\"))"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#by",
    "href": "posts/collapse_cheat_sheet/index.html#by",
    "title": "Collapse Cheat sheet",
    "section": "by",
    "text": "by\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt; \n  fgroup_by(ch)|&gt;\n  fsummarise(sumrf = fsum(realf)) # ordered and indexed results\n\n# Assigned column name\n\ndf |&gt; \n  fgroup_by(abc = tolower(ch))|&gt;\n  fsummarise(sumrf = fsum(realf))\n\n# Add a column with number of observations for each group\n\ndf |&gt;\n  fgroup_by(ch)|&gt;\n  fcount(add = TRUE)\n\n\n\n\ndt[, .(sumrf = sum(realf)), by = \"ch\"] # unordered results\n\n# Reordered and indented:\n\ndt[, keyby = ch,\n     .(sumrf = sum(realf))]\n\n# Assigning column name\n\ndt[, keyby = .(abc = tolower(ch)),\n     .(sumrf = sum(realf))]\n\n# Add a column with number of observations for each group\n\ndt[, n := .N, by = ch][]\ndt[, n := NULL] # remove for consistency\n\n\n\n\ntb |&gt; \n  group_by(ch)|&gt;\n  summarise(sumrf = sum(realf)) # ordered results\n\n# Assigned column name\n\ntb |&gt; \n  group_by(abc = tolower(ch))|&gt;\n  summarise(sumrf = sum(realf))\n\n# Add a column with number of observations for each group\n\ntb |&gt;\n  group_by(ch)|&gt;\n  add_tally()\n\n# or...\n\nadd_count(tb, ch)"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#going-further",
    "href": "posts/collapse_cheat_sheet/index.html#going-further",
    "title": "Collapse Cheat sheet",
    "section": "Going further",
    "text": "Going further\n\nAdvanced columns manipulation\n\ncollapsedata.tabledplyr\n\n\n\n# Summarize columns\ndf |&gt;\n  fsummarise(across(c(\"realf\", \"reald\"),\n            fmean))\n\n# Summarize using a condition\ndf |&gt;\n  fsummarise(across(is.numeric, # different from dplyr due to across\n                   fmean))\n\n# Modify all the columns\ndf |&gt; \n  fmutate(across(NULL,rev))\n\n# Modify several columns\ndf |&gt; \n  fcomputev(vars = c(\"realf\", \"reald\"), # dropping the other columns\n                  sqrt)\n\ndf &lt;- df |&gt;\n  ftransformv(vars = c(\"realf\", \"reald\"), # keeping the other columns\n                sqrt)\n\ndf &lt;- df |&gt;\n  ftransformv(vars = c(\"realf\", \"reald\"), # reverting for consistency\n                FUN = function(x){ x^2 })\n\n# Modify columns using a condition \n\ndf |&gt;\n  fcomputev(is.numeric,\n           FUN = function(x){x - 1})\n\n\n\n\n# Summarize columns\ndt[, lapply(.SD, mean),\n   .SDcols = c(\"realf\", \"reald\")]\n\n# Summarize using a condition\ndt[, lapply(.SD, mean),\n     .SDcols = is.numeric]\n\n# Modify all the columns\ndt[, lapply(.SD, rev)]\n\n# Modify several columns\ndt[, lapply(.SD, sqrt), # dropping the other columns\n     .SDcols = realf:reald]\n\ncols &lt;- c(\"realf\", \"reald\")\n\ndt[, (cols) := lapply(.SD, sqrt), # keeping the other columns\n     .SDcols = cols]\n\ndt[, (cols) := lapply(.SD, \"^\", 2L), # reverting for consistency\n     .SDcols = cols]\n\n# Modify columns using a condition \ndt[, .SD - 1,\n     .SDcols = is.numeric] \n\nrm(cols)\n\n\n\n\n# Summarize columns\ntb |&gt;\n  summarise(across(c(\"realf\", \"reald\"),\n            mean))\n\n# Summarize using a condition\ntb |&gt;\n  summarise(across(where(is.numeric),\n                   mean))\n\n# Modify all the columns\ntb |&gt; \n  mutate(across(everything(),\n                rev))\n\n# Modify several columns\ntb |&gt;\n  transmute(across(c(\"realf\", \"reald\"), # dropping the other columns\n                  sqrt))\n\ntb &lt;- tb |&gt;\n  mutate(across(all_of(c(\"realf\", \"reald\")), # keeping the other columns\n                sqrt))\n\ntb &lt;- tb |&gt;\n  mutate(across(all_of(c(\"realf\", \"reald\")), # reverting for consistency\n                ~ \"^\"(.x, 2L)))\n\n# Modify columns using a condition \n\ntb |&gt;\n  transmute(across(where(is.numeric), \n                   ~ '-'(., 1L)))\n\n\n\n\n\n\nChain expressions\n\ncollapsedata.tabledplyr\n\n\n\ndf |&gt;\n  fgroup_by(ch)|&gt;\n  fsummarise(sumrf = fsum(realf))|&gt;\n  fsubset(sumrf &lt; 129000)\n\n\n\n\ndt[, by = ch,\n   .(sumrf = sum(realf))][\n     sumrf &lt; 129000\n   ]\n\n\n\n\ntb |&gt;\n  group_by(ch)|&gt;\n  summarise(sumrf = sum(realf))|&gt;\n  filter(sumrf &lt; 129000)\n\n\n\n\n\n\nIndexing and keys (not sure it applies)\n\n\nset modifications\n\ncollapsedata.tabledplyr\n\n\n\n# Replace values (recommendation to use set of data.table)\n\nset(df, i = 1L, j = 2L, value = 30L) \n\n# Reorder rows\n\ndf &lt;- roworder(df, id2, -id1)\n\ndf &lt;- roworder(df, id1) # reversal for consistency\n\n# Modify column names\n\ndf &lt;- frename(df, dt = date)\n\ndf &lt;- frename(df, date = dt) # reversal for consistency\n\n# reorder columns\n\ndf &lt;- colorder(df, id1, id2, ch)\n\n\n\n\n# Replace values\n\nset(dt, i = 1L, j = 2L, value = 30L)\n\n# Reorder rows\n\nsetorder(dt, id2, -id1)\n\nsetorder(dt, id1) # reversal for consistency\n\n# Modify column names\n\nsetnames(dt, old = \"dt\", new = \"date\")\n\nsetnames(dt, old = \"date\", new = \"dt\")  # reversal for consistency\n\n# reorder columns\n\nsetcolorder(dt, c(\"id1\",\"id2\",\"ch\"))\n\n\n\n\n# Replace values\n\ntb[1,2] &lt;- 30L\n\n# Reorder rows\n\ntb &lt;- arrange(tb, id2, desc(id1))\n\ntb &lt;- arrange(tb, id1) # reversal for consistency\n\n# Modify column names\n\ntb &lt;- rename(tb, date = dt)\n\ntb &lt;- rename(tb, dt = date) # reversal for consistency\n\n# reorder columns\n\ntb &lt;- relocate(tb, c(\"id1\", \"id2\", \"ch\"))\n\n\n\n\n\n\nAdvanced use of by (maybe)"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#joinbind-data-sets",
    "href": "posts/collapse_cheat_sheet/index.html#joinbind-data-sets",
    "title": "Collapse Cheat sheet",
    "section": "Join/Bind data sets",
    "text": "Join/Bind data sets\n\nBind\n\ncollapsedata.tabledplyr\n\n\n\nx &lt;- data.table(1:3)\ny &lt;- data.table(4:6)\nz &lt;- data.table(7:9, 0L)\n\n# bind rows\n\nrowbind(x, y, fill = TRUE) # always fills\n\n# bind rows using a list\n\nrowbind(list(x, y), idcol = \"id\")\n\n# bind columns\n\nbase::cbind(x, y)\n\nadd_vars(x) &lt;- y # modifies x but keeps data structure and attributes\n\n\n\n\nx &lt;- data.table(1:3)\ny &lt;- data.table(4:6)\nz &lt;- data.table(7:9, 0L)\n\n# bind rows\n\nrbind(x, y, fill = TRUE)\n\n# bind rows using a list\n\nrbindlist(list(x, y), idcol = \"id\")\n\n# bind columns\n\nbase::cbind(x, y)\n\nx &lt;- base::cbind(x, y) # modifies x but column names are not changed\n\n\n\n\nx &lt;- data.table(1:3)\ny &lt;- data.table(4:6)\nz &lt;- data.table(7:9, 0L)\n\n# bind rows\n\nbind_rows(x, y) # always fills\n\n# bind rows using a list\n\nbind_rows(list(x, y), .id = \"id\")\n\n# bind columns\n\nbind_cols(x, y)\n\nx &lt;- bind_cols(x, y) # modifies x and replace names"
  },
  {
    "objectID": "posts/collapse_cheat_sheet/index.html#efficient-functions-maybe",
    "href": "posts/collapse_cheat_sheet/index.html#efficient-functions-maybe",
    "title": "Collapse Cheat sheet",
    "section": "Efficient functions (maybe)",
    "text": "Efficient functions (maybe)"
>>>>>>> collapse_cheat_sheet
  }
]